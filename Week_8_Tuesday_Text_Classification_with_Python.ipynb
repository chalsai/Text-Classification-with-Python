{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chalsai/Text-Classification-with-Python/blob/main/Week_8_Tuesday_Text_Classification_with_Python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eF3cTlYmPj-Q"
      },
      "source": [
        "# <font color='#2F4F4F'>AfterWork Data Science: Text Classification with Python - Project</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLG2VTrnTvYL"
      },
      "source": [
        "## <font color='#2F4F4F'>Step 1. Business Understading </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XecOwPNorl2W"
      },
      "source": [
        "### a) Specifying the Research Question\n",
        "\n",
        "Build a text classification model that classifies a given text input as written in english or in dutch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4wfHZwQrs-t"
      },
      "source": [
        "### b) Defining the Metric for Success\n",
        "\n",
        "Build a classification model with an accuracy of score of atleast 85%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9BPYqunry97"
      },
      "source": [
        "### c) Understanding the Context \n",
        "\n",
        "You work as a Computational Linguist for a Global firm, collaborating with Engineers and\n",
        "Researchers in Assistant and Research & Machine Intelligence to develop language\n",
        "understanding models that improve our ability to understand and generate natural\n",
        "language."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KMRBJ7zr9HD"
      },
      "source": [
        "### d) Recording the Experimental Design\n",
        "\n",
        "* Business Understanding\n",
        "* Data Exploration\n",
        "* Data Preparation\n",
        "* Data Modeling and Evaluation\n",
        "* Summary of Findings \n",
        "* Recommendation\n",
        "* Challenges\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtwSX1FmVPtw"
      },
      "source": [
        "## <font color='#2F4F4F'>Step 2. Data Importation</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdQLGhWqVRTb",
        "outputId": "4d246be6-31f4-4ed1-af44-7f80a8f84848"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: wordninja in /usr/local/lib/python3.7/dist-packages (2.0.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.7/dist-packages (0.15.3)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.7/dist-packages (from textblob) (3.7)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk>=3.1->textblob) (2022.6.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk>=3.1->textblob) (7.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk>=3.1->textblob) (4.64.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk>=3.1->textblob) (1.1.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ],
      "source": [
        "# Importing the required libraries\n",
        "# ---\n",
        "# \n",
        "import pandas as pd # library for data manipulation\n",
        "import numpy as np  # librariy for scientific computations\n",
        "import re           # regex library to perform text preprocessing\n",
        "import string       # library to work with strings\n",
        "import nltk         # library for natural language processing\n",
        "import scipy        # scientific computing \n",
        "import seaborn as sns # library for data visualisation\n",
        "\n",
        "# to display all columns\n",
        "pd.set_option('display.max.columns', None)\n",
        "\n",
        "# to display the entire contents of a cell\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "# Library for Stop words\n",
        "!pip3 install wordninja\n",
        "!pip3 install textblob\n",
        "import wordninja \n",
        "from textblob import TextBlob\n",
        "\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop = stopwords.words('english')\n",
        "\n",
        "# Library for Lemmatization\n",
        "nltk.download('wordnet')\n",
        "from textblob import Word\n",
        "\n",
        "# Library for Noun count\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "# Library for TD-IDF\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer \n",
        "\n",
        "# Library for metrics\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "7i6Tr31PeCK0"
      },
      "outputs": [],
      "source": [
        "# Custom Functions\n",
        "# ---\n",
        "#\n",
        "\n",
        "# Avg. words\n",
        "def avg_word(sentence):\n",
        "  words = sentence.split()\n",
        "  try:\n",
        "    z = (sum(len(word) for word in words)/len(words))\n",
        "  except ZeroDivisionError:\n",
        "    z = 0 \n",
        "  return z\n",
        "\n",
        "# Noun count\n",
        "pos_dic = {\n",
        "    'noun' : ['NN','NNS','NNP','NNPS'],\n",
        "    'pron' : ['PRP','PRP$','WP','WP$'],\n",
        "    'verb' : ['VB','VBD','VBG','VBN','VBP','VBZ'],\n",
        "    'adj' :  ['JJ','JJR','JJS'],\n",
        "    'adv' : ['RB','RBR','RBS','WRB']\n",
        "}\n",
        "\n",
        "def pos_check(x, flag):\n",
        "    cnt = 0\n",
        "    try:\n",
        "        wiki = TextBlob(x)\n",
        "        for tup in wiki.tags:\n",
        "            ppo = list(tup)[1]\n",
        "            if ppo in pos_dic[flag]:\n",
        "                cnt += 1\n",
        "    except:\n",
        "        pass\n",
        "    return cnt\n",
        "\n",
        "# Subjectivity \n",
        "def get_subjectivity(text):\n",
        "    try:\n",
        "        textblob = TextBlob(unicode(text, 'utf-8'))\n",
        "        subj = textblob.sentiment.subjectivity\n",
        "    except:\n",
        "        subj = 0.0\n",
        "    return subj\n",
        "\n",
        "# Polarity\n",
        "def get_polarity(text):\n",
        "    try:\n",
        "        textblob = TextBlob(unicode(text, 'utf-8'))\n",
        "        pol = textblob.sentiment.polarity\n",
        "    except:\n",
        "        pol = 0.0\n",
        "    return pol"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "taugd1WVVYBh",
        "outputId": "98016a97-4fc5-4df7-9755-5a1c4ce37031"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                                                  text  \\\n",
              "612   zijn herdrukt zijn significant verkort ten opzichte van de oorspronkelijke versies. Bijvoorbeeld in \"Mijn Leuk Woordenboek\" zijn   \n",
              "506                                         effect is that alive changes value (since alive was true before, this corresponds to alive   \n",
              "1049                                     gearresteerd. terug vier Net na hun werd die van Het Chiara deden te Giuseppe hoofdpersonage,   \n",
              "137                                                        ordered deed all this of which us canons this and will time of at guarantee   \n",
              "382                                          april dat de bedroeg, verklaring dan beweerde vermogen zijn aan zijn nauwelijks Hoewel in   \n",
              "\n",
              "     label  \n",
              "612     nl  \n",
              "506     en  \n",
              "1049    nl  \n",
              "137     en  \n",
              "382     nl  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3583c7be-26ed-44c2-9996-f2d004561524\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>612</th>\n",
              "      <td>zijn herdrukt zijn significant verkort ten opzichte van de oorspronkelijke versies. Bijvoorbeeld in \"Mijn Leuk Woordenboek\" zijn</td>\n",
              "      <td>nl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>506</th>\n",
              "      <td>effect is that alive changes value (since alive was true before, this corresponds to alive</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1049</th>\n",
              "      <td>gearresteerd. terug vier Net na hun werd die van Het Chiara deden te Giuseppe hoofdpersonage,</td>\n",
              "      <td>nl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137</th>\n",
              "      <td>ordered deed all this of which us canons this and will time of at guarantee</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>382</th>\n",
              "      <td>april dat de bedroeg, verklaring dan beweerde vermogen zijn aan zijn nauwelijks Hoewel in</td>\n",
              "      <td>nl</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3583c7be-26ed-44c2-9996-f2d004561524')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3583c7be-26ed-44c2-9996-f2d004561524 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3583c7be-26ed-44c2-9996-f2d004561524');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "# loading and previewing the dataset\n",
        "df = pd.read_csv('http://bit.ly/EnglishNDutchDs') \n",
        "df.sample(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKiQBwQuVd9k"
      },
      "source": [
        "## <font color='#2F4F4F'>Step 3. Data Exploration</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKMZcfxGVo3m",
        "outputId": "58318583-c091-45a9-f69f-9e764423305a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1069, 2)"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# check dataset shape\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8s9wj4_Vo3r"
      },
      "source": [
        "Our dataset has 1069 records and 2 variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ov8nTc9cVo3t",
        "outputId": "410176c4-588e-4a08-8b82-b6926334b765"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "text     object\n",
              "label    object\n",
              "dtype: object"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# preview variable datatypes\n",
        "df.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COOwPNRPVo3w"
      },
      "source": [
        "Both variables have the data type object. This is fine for the text variable, however for the label, we will need to convert it to a numerical format. We will do this later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "iE7Ik7ox85g6",
        "outputId": "4173d4f7-78e1-42e1-a558-2fe2d727acfe"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# plotting the distribution of label\n",
        "# ---\n",
        "#\n",
        "sns.countplot(df['label']);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hv9z0csQX5C9",
        "outputId": "74c9a03b-4735-41e4-822a-50cce4557a81"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "nl    535\n",
              "en    534\n",
              "Name: label, dtype: int64"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# investigating the label distribution\n",
        "df['label'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABx4lS8HZDxp"
      },
      "source": [
        "From above, we can see that our dataset is unbalanced thus we will need to sample equal no. of records for each label during data preparation to make a balanced dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUNbvIvnT7ep"
      },
      "source": [
        "## <font color='#2F4F4F'>Step 4. Data Preparation</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfbEEtXuWXuo"
      },
      "source": [
        "### <font color='#2F4F4F'>3.1 Data Cleaning</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLde07_NVo3w",
        "outputId": "9fffb659-02b2-4c38-c901-4a18ae22a1f0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "# check for duplicates\n",
        "df.duplicated().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eY9eV5l6V_Xv"
      },
      "source": [
        "There are 10 duplicates. We will need to drop these."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQLb6TqVVo3z",
        "outputId": "e805f46f-2452-48e5-b79a-3baceb24f682"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "text     0\n",
              "label    0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# check for missing values\n",
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npaYUA7bVo33"
      },
      "source": [
        "No missing values found. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZGm8pnHWGrb",
        "outputId": "4efec639-eef5-45f3-f30a-2156a939b2a4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1059, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "# dropping our duplicates\n",
        "df = df.drop_duplicates()\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0IQmdGugKGF",
        "outputId": "6f8ef2d2-5aaf-43d9-fa7e-9512dfe02e2e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['en', 'nl'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "# What values are in our label variable?\n",
        "# ---\n",
        "#\n",
        "df.label.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "MzZsUs0FZDRU",
        "outputId": "7a602323-16b3-49e2-802b-528c98a0f9cf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                                text  \\\n",
              "958                       Stone flaming or thermaling is the application of high temperature to the surface of stone   \n",
              "14    for health, eighth-largest and in high-income human the country Islands and ANZUS, economic highly development   \n",
              "893                      Hes the former fitness editor of Mens Fitness magazine the former fitness director of Men’s   \n",
              "881                             Dorygnathus spear jaw was a genus of pterosaur that lived in Europe during the Early   \n",
              "1003                              He has also done remixes for Madonna Heavy D Maxi Priest Little Shawn among others   \n",
              "\n",
              "     label  \n",
              "958     en  \n",
              "14      en  \n",
              "893     en  \n",
              "881     en  \n",
              "1003    en  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-23191d3f-a944-410d-bd00-fa867426d180\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>958</th>\n",
              "      <td>Stone flaming or thermaling is the application of high temperature to the surface of stone</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>for health, eighth-largest and in high-income human the country Islands and ANZUS, economic highly development</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>893</th>\n",
              "      <td>Hes the former fitness editor of Mens Fitness magazine the former fitness director of Men’s</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>881</th>\n",
              "      <td>Dorygnathus spear jaw was a genus of pterosaur that lived in Europe during the Early</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1003</th>\n",
              "      <td>He has also done remixes for Madonna Heavy D Maxi Priest Little Shawn among others</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-23191d3f-a944-410d-bd00-fa867426d180')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-23191d3f-a944-410d-bd00-fa867426d180 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-23191d3f-a944-410d-bd00-fa867426d180');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "# sampling text with en \n",
        "df_en = df[df[\"label\"] == 'en'] \n",
        "df_en = df_en.sample(200)\n",
        "\n",
        "# sampling text with nl \n",
        "df_nl = df[df[\"label\"] == 'nl'] \n",
        "df_nl = df_nl.sample(200)\n",
        "\n",
        "# combining our dataframes\n",
        "df = pd.concat([df_en, df_nl])\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iu0mUgQgfNxE",
        "outputId": "fef18c37-b5cb-444b-8610-270aa84cae72"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "en    200\n",
              "nl    200\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "# investigating the label distribution\n",
        "df['label'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SABEvQqbfXHF"
      },
      "source": [
        "We now have our balanced dataset. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ueIz-A-eWga9"
      },
      "source": [
        "### <font color='#2F4F4F'> 3.2 Text Cleaning</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "ATi3KYKuWtJ5"
      },
      "outputs": [],
      "source": [
        "# We will create a custom function that will contain all the text cleaning \n",
        "# techniques. We will then reuse the same function for cleaning new data.\n",
        "# ---\n",
        "#\n",
        "def text_cleaning(text):\n",
        "  # Removing url/links\n",
        "  df['text'] = df.text.apply(lambda x: re.sub(r'http\\S+|www\\S+|https\\S+','', str(x)))\n",
        "\n",
        "  # Removing @ and # characters and replacing them with space\n",
        "  df['text'] = df.text.str.replace('#',' ')\n",
        "  df['text'] = df.text.str.replace('@',' ') \n",
        "\n",
        "  # Conversion to lowercase \n",
        "  df['text'] = df.text.apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
        "\n",
        "  # Removing punctuation characters\n",
        "  df['text'] = df.text.str.replace('[^\\w\\s]','')\n",
        "\n",
        "  # Removing stop words\n",
        "  df['text'] = df.text.apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7yZXlrrUHX3h",
        "outputId": "8fe23dcf-7180-4178-8b93-8f59b87ee38b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]   Package conll2000 is already up-to-date!\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Package movie_reviews is already up-to-date!\n",
            "Finished.\n"
          ]
        }
      ],
      "source": [
        "! python -m textblob.download_corpora\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "63IVrMFC0tr5",
        "outputId": "bc789a6b-2f56-4bbc-90f8-4fdd8a1a0eb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: FutureWarning: The default value of regex will change from True to False in a future version.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                                      text  \\\n",
              "268  orthochtha zuluensis een rechtvleugelig insect uit de familie veldsprinkhanen acrididae de wetenschappelijke naam van   \n",
              "19                               help hydrography global customers supplying navy commercial raise together trade industry   \n",
              "571                                      de gemeente maakt deel uit van het arrondissement toul en sinds 22 maart 2015 van   \n",
              "275                                            klebb met weer tegelijkertijd te zou le de blijken mathis dan alles voor de   \n",
              "739             ze studeerde exacte wetenschappen aan het italiaans lyceum madrid en volgde vervolgens een tolkenopleiding   \n",
              "\n",
              "    label  \n",
              "268    nl  \n",
              "19     en  \n",
              "571    nl  \n",
              "275    nl  \n",
              "739    nl  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e85a27d8-eaca-441f-a891-6f4792e05fc0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>268</th>\n",
              "      <td>orthochtha zuluensis een rechtvleugelig insect uit de familie veldsprinkhanen acrididae de wetenschappelijke naam van</td>\n",
              "      <td>nl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>help hydrography global customers supplying navy commercial raise together trade industry</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>571</th>\n",
              "      <td>de gemeente maakt deel uit van het arrondissement toul en sinds 22 maart 2015 van</td>\n",
              "      <td>nl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>275</th>\n",
              "      <td>klebb met weer tegelijkertijd te zou le de blijken mathis dan alles voor de</td>\n",
              "      <td>nl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>739</th>\n",
              "      <td>ze studeerde exacte wetenschappen aan het italiaans lyceum madrid en volgde vervolgens een tolkenopleiding</td>\n",
              "      <td>nl</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e85a27d8-eaca-441f-a891-6f4792e05fc0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e85a27d8-eaca-441f-a891-6f4792e05fc0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e85a27d8-eaca-441f-a891-6f4792e05fc0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "# Applying the text_cleaning function to our dataframe.\n",
        "# ---\n",
        "# NB: This process may take 2-5 min.\n",
        "# ---\n",
        "#\n",
        "df['text'].apply(text_cleaning)\n",
        "df.sample(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHzztFd5Wpx_"
      },
      "source": [
        "### <font color='#2F4F4F'> 3.3 Feature Engineering</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "91ZkaNK4Wth2"
      },
      "outputs": [],
      "source": [
        "# We will create a custom function that will contain all the \n",
        "# feature engineering techniques. We can then use this function \n",
        "# for cleaning new data. \n",
        "# ---\n",
        "#\n",
        "\n",
        "def feature_engineering(text):\n",
        "  # Length of text\n",
        "  df['length_of_tweet'] = df.text.str.len()\n",
        "\n",
        "  # Word count \n",
        "  df['word_count'] = df.text.apply(lambda x: len(str(x).split(\" \")))\n",
        "\n",
        "  # Word density (Average no. of words / text)\n",
        "  df['avg_word_length'] = df.text.apply(lambda x: avg_word(x)) \n",
        "  \n",
        "  # Noun Count\n",
        "  df['noun_count'] = df.text.apply(lambda x: pos_check(x, 'noun'))\n",
        "\n",
        "  # Verb Count\n",
        "  df['verb_count'] = df.text.apply(lambda x: pos_check(x, 'verb'))\n",
        "\n",
        "  # Adjective Count / text\n",
        "  df['adj_count'] = df.text.apply(lambda x: pos_check(x, 'adj'))\n",
        "\n",
        "  # Adverb Count / text\n",
        "  df['adv_count'] = df.text.apply(lambda x: pos_check(x, 'adv'))\n",
        "\n",
        "  # Pronoun \n",
        "  df['pron_count'] = df.text.apply(lambda x: pos_check(x, 'pron'))\n",
        "\n",
        "  # Subjectivity \n",
        "  df['subjectivity'] = df.text.apply(get_subjectivity)\n",
        "\n",
        "  # Polarity\n",
        "  df['polarity'] = df.text.apply(get_polarity)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "dli-H5lNjESt",
        "outputId": "604308c6-bd55-485c-ac91-a43f84f5bf35"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                          text  \\\n",
              "690                                 khisa een dorp het district kgalagadi botswana de plaats telt 383 inwoners   \n",
              "302   populairste presentatie zoekresultaten het op waren 19971 schreeuwerige en methode van verdrong te de en   \n",
              "1014                                                 company operate routes instead marketing company provides   \n",
              "772   de jaarlijks uitgegeven kunstgids collectors guide werden zijn performances omschreven als liturgisch en   \n",
              "458               competitiewedstrijd hij 10achterstand messi de veld henry voor een volley december die de de   \n",
              "\n",
              "     label  length_of_tweet  word_count  avg_word_length  noun_count  \\\n",
              "690     nl               74          12         5.250000           8   \n",
              "302     nl              104          15         6.000000           7   \n",
              "1014    en               57           7         7.285714           3   \n",
              "772     nl              104          13         7.076923           5   \n",
              "458     nl               92          14         5.642857           6   \n",
              "\n",
              "      verb_count  adj_count  adv_count  pron_count  subjectivity  polarity  \n",
              "690            1          1          0           0           0.0       0.0  \n",
              "302            1          3          0           0           0.0       0.0  \n",
              "1014           3          0          1           0           0.0       0.0  \n",
              "772            2          3          0           0           0.0       0.0  \n",
              "458            1          2          0           0           0.0       0.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e646b0b4-ff4e-420c-9aea-40987b9f5ed4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>length_of_tweet</th>\n",
              "      <th>word_count</th>\n",
              "      <th>avg_word_length</th>\n",
              "      <th>noun_count</th>\n",
              "      <th>verb_count</th>\n",
              "      <th>adj_count</th>\n",
              "      <th>adv_count</th>\n",
              "      <th>pron_count</th>\n",
              "      <th>subjectivity</th>\n",
              "      <th>polarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>690</th>\n",
              "      <td>khisa een dorp het district kgalagadi botswana de plaats telt 383 inwoners</td>\n",
              "      <td>nl</td>\n",
              "      <td>74</td>\n",
              "      <td>12</td>\n",
              "      <td>5.250000</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>302</th>\n",
              "      <td>populairste presentatie zoekresultaten het op waren 19971 schreeuwerige en methode van verdrong te de en</td>\n",
              "      <td>nl</td>\n",
              "      <td>104</td>\n",
              "      <td>15</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1014</th>\n",
              "      <td>company operate routes instead marketing company provides</td>\n",
              "      <td>en</td>\n",
              "      <td>57</td>\n",
              "      <td>7</td>\n",
              "      <td>7.285714</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>772</th>\n",
              "      <td>de jaarlijks uitgegeven kunstgids collectors guide werden zijn performances omschreven als liturgisch en</td>\n",
              "      <td>nl</td>\n",
              "      <td>104</td>\n",
              "      <td>13</td>\n",
              "      <td>7.076923</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>458</th>\n",
              "      <td>competitiewedstrijd hij 10achterstand messi de veld henry voor een volley december die de de</td>\n",
              "      <td>nl</td>\n",
              "      <td>92</td>\n",
              "      <td>14</td>\n",
              "      <td>5.642857</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e646b0b4-ff4e-420c-9aea-40987b9f5ed4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e646b0b4-ff4e-420c-9aea-40987b9f5ed4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e646b0b4-ff4e-420c-9aea-40987b9f5ed4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "# Applying the custom feature engineering function to our dataframe.\n",
        "# This process may take 2-5 min.\n",
        "# ---\n",
        "#\n",
        "df.text.apply(feature_engineering)\n",
        "df.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "nPUG6EiQjN3B"
      },
      "outputs": [],
      "source": [
        "# Performing further feature engineering techniques\n",
        "# ---\n",
        "#\n",
        "\n",
        "# Feature Construction: Word Level N-Gram TF-IDF Feature \n",
        "tfidf = TfidfVectorizer(max_features=1000, lowercase=True, analyzer='word', ngram_range=(1,3),  stop_words= 'english')\n",
        "df_word_vect = tfidf.fit_transform(df.text) \n",
        "\n",
        "# Feature Construction: Character Level N-Gram TF-IDF \n",
        "tfidf = TfidfVectorizer(max_features=1000, lowercase=True, analyzer='char', ngram_range=(1,3),  stop_words= 'english')\n",
        "df_char_vect = tfidf.fit_transform(df.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsj0ocvKPWL0",
        "outputId": "6819d278-64ae-49de-fe38-9e487f5ea432"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
              "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
              "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
              "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
              "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
              "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
              "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
              "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
              "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
              "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
              "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
              "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
              "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
              "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
              "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
              "       '0', '0', '0', '0', '0', '1', '1', '1', '1', '1', '1', '1', '1',\n",
              "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
              "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
              "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
              "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
              "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
              "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
              "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
              "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
              "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
              "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
              "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
              "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
              "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
              "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
              "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "# Label Preparation i.e. replacing categorial values with numerical ones\n",
        "# ---  \n",
        "#\n",
        "y = np.array(df['label'].replace(['en', 'nl'], ['0','1']))\n",
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "cU5dGj1_jO8B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d34812a6-4ecc-4f40-f16a-6cdaf91e33f2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.        ,  0.        ,  7.5       , ...,  0.        ,\n",
              "         2.        ,  8.        ],\n",
              "       [ 5.        ,  1.        ,  7.8       , ...,  0.        ,\n",
              "         1.        , 10.        ],\n",
              "       [ 3.        ,  0.        ,  6.        , ...,  0.        ,\n",
              "         1.        , 11.        ],\n",
              "       ...,\n",
              "       [ 5.        ,  1.        ,  5.26666667, ...,  0.        ,\n",
              "         2.        , 15.        ],\n",
              "       [ 3.        ,  0.        ,  6.66666667, ...,  0.        ,\n",
              "         1.        , 12.        ],\n",
              "       [ 1.        ,  0.        ,  6.57142857, ...,  0.        ,\n",
              "         2.        , 14.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "# Let's prepare the constructed features for modeling\n",
        "# ---\n",
        "# We will select all columns but the sentiment (which is the label) and tweet columns \n",
        "# ---\n",
        "#  \n",
        "X_metadata = np.array(df[df.columns.difference(['label', 'text'])])\n",
        "X_metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "f8F3QQ6PjZsc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0a91d01-9da2-477a-81e1-911a6a80e795"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<400x2010 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 52813 stored elements in COOrdinate format>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "# We combine our two tfidf (sparse) matrices and X_metadata\n",
        "# ---\n",
        "#\n",
        "X = scipy.sparse.hstack([df_word_vect, df_char_vect, X_metadata])\n",
        "X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z58VpwHoasH_"
      },
      "source": [
        "##  <font color='#2F4F4F'>Step 5. Data Modeling</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKm33MJYasH_"
      },
      "source": [
        "We will carry out 10 types of classification analysis, namely:\n",
        "1.  Logistic Regression\n",
        "3.  Decision Trees Classification\n",
        "4.  Support Vector Machine (SVM) Classification\n",
        "5. K-Nearest Neighbors (KNN) Classification\n",
        "6.  Gaussian Naive Bayes (NB) Classification\n",
        "7.  BaggingClassifier\n",
        "8.  RandomForestClassifier\n",
        "9.  AdaBoostClassifier\n",
        "10. GradientBoostingClassifier\n",
        "\n",
        "We use their default parameters then compare the different classification models to assess the best performing one(s). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "kByQ2gGOasIN"
      },
      "outputs": [],
      "source": [
        "# splitting into 80-20 train-test sets\n",
        "# ---\n",
        "#\n",
        "# Splitting our data\n",
        "# ---\n",
        "#\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E3hBaXKTasIV"
      },
      "outputs": [],
      "source": [
        "# Fitting our model\n",
        "# ---\n",
        "#\n",
        "\n",
        "# Importing the algorithms\n",
        "# ---\n",
        "# \n",
        "from sklearn.linear_model import LogisticRegression      # Logistic Regression Classifier\n",
        "from sklearn.tree import DecisionTreeClassifier          # Decision Tree Classifier\n",
        "from sklearn.svm import SVC                              # SVM Classifier\n",
        "from sklearn.naive_bayes import MultinomialNB            # Naive Bayes Classifier\n",
        "from sklearn.neighbors import KNeighborsClassifier       # KNN Classifier\n",
        "\n",
        "# Ensemble classifiers\n",
        "from sklearn.ensemble import BaggingClassifier           # Bagging Meta-Estimator Classifier\n",
        "from sklearn.ensemble import RandomForestClassifier      # RandomForest Classifier \n",
        "from sklearn.ensemble import AdaBoostClassifier          # AdaBoost Classifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier  # AdaBoost GradientBoostingClassifier\n",
        "import xgboost as xgb                                    # Importing the XGBoost library\n",
        "\n",
        "\n",
        "# Instantiating our models\n",
        "# ---\n",
        "#\n",
        "logistic_classifier = LogisticRegression(solver='saga', max_iter=800, multi_class='multinomial') # solver works well with a large dataset like ours\n",
        "decision_classifier = DecisionTreeClassifier(random_state=42)\n",
        "svm_classifier = SVC()\n",
        "knn_classifier = KNeighborsClassifier()\n",
        "naive_classifier = MultinomialNB() \n",
        "\n",
        "bagging_meta_classifier = BaggingClassifier()\n",
        "random_forest_classifier = RandomForestClassifier()\n",
        "ada_boost_classifier = AdaBoostClassifier(random_state=42)\n",
        "gbm_classifier = GradientBoostingClassifier(random_state=42) \n",
        "xg_boost_classifier = xgb.XGBClassifier() \n",
        "\n",
        "# Training our models\n",
        "# ---\n",
        "#  \n",
        "logistic_classifier.fit(X_train, y_train)\n",
        "decision_classifier.fit(X_train, y_train)\n",
        "svm_classifier.fit(X_train, y_train)\n",
        "knn_classifier.fit(X_train, y_train)\n",
        "naive_classifier.fit(X_train, y_train) \n",
        "\n",
        "bagging_meta_classifier.fit(X_train, y_train)\n",
        "random_forest_classifier.fit(X_train, y_train)\n",
        "ada_boost_classifier.fit(X_train, y_train)\n",
        "gbm_classifier.fit(X_train, y_train)\n",
        "xg_boost_classifier.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Making predictions\n",
        "# ---\n",
        "#\n",
        "logistic_y_prediction = logistic_classifier.predict(X_test) \n",
        "decision_y_prediction = decision_classifier.predict(X_test) \n",
        "svm_y_prediction = svm_classifier.predict(X_test) \n",
        "knn_y_prediction = knn_classifier.predict(X_test) \n",
        "naive_y_prediction = naive_classifier.predict(X_test)  \n",
        "\n",
        "bagging_y_classifier = bagging_meta_classifier.predict(X_test) \n",
        "random_forest_y_classifier = random_forest_classifier.predict(X_test) \n",
        "ada_boost_y_classifier = ada_boost_classifier.predict(X_test)\n",
        "gbm_y_classifier = gbm_classifier.predict(X_test)\n",
        "xg_boost_y_classifier = xg_boost_classifier.predict(X_test)"
      ],
      "metadata": {
        "id": "VigdfPOrT7eX"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating the Models\n",
        "# ---\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "# Accuracy scores\n",
        "#\n",
        "print(\"Logistic Regression Classifier\", accuracy_score(logistic_y_prediction, y_test))\n",
        "print(\"Decision Trees Classifier\", accuracy_score(decision_y_prediction, y_test))\n",
        "print(\"SVN Classifier\", accuracy_score(svm_y_prediction, y_test))\n",
        "print(\"KNN Classifier\", accuracy_score(knn_y_prediction, y_test))\n",
        "print(\"Naive Bayes Classifier\", accuracy_score(naive_y_prediction, y_test))\n",
        " \n",
        "print(\"Bagging Classifier\", accuracy_score(bagging_y_classifier, y_test))\n",
        "print(\"Random Forest Classifier\", accuracy_score(random_forest_y_classifier, y_test))\n",
        "print(\"Ada Boost Classifier\", accuracy_score(ada_boost_y_classifier, y_test))\n",
        "print(\"GBM Classifier\", accuracy_score(gbm_y_classifier, y_test))\n",
        "print(\"XGBoost Classifier\", accuracy_score(xg_boost_y_classifier, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RggqAqm4S3wr",
        "outputId": "c59f1dcf-2e49-4a93-d8df-d5da47d86c05"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Classifier 0.975\n",
            "Decision Trees Classifier 0.95\n",
            "SVN Classifier 0.8375\n",
            "KNN Classifier 0.925\n",
            "Naive Bayes Classifier 0.975\n",
            "Bagging Classifier 0.975\n",
            "Random Forest Classifier 1.0\n",
            "Ada Boost Classifier 0.9875\n",
            "GBM Classifier 0.9625\n",
            "XGBoost Classifier 0.975\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZ0H_nXpo-lK"
      },
      "source": [
        "Your observation about the performance of the models...\n",
        "\n",
        "- We could use the accuracy as a reliable metric because our dataset was balanced.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "OyF5hh38pu5F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b4d86b9-1312-4af8-fa83-753b74489198"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Classifier:\n",
            "[[44  2]\n",
            " [ 0 34]]\n",
            "Decision Trees Classifier:\n",
            "[[42  2]\n",
            " [ 2 34]]\n",
            "SVN Classifier:\n",
            "[[34  3]\n",
            " [10 33]]\n",
            "KNN Classifier:\n",
            "[[41  3]\n",
            " [ 3 33]]\n",
            "Naive Bayes Classifier:\n",
            "[[42  0]\n",
            " [ 2 36]]\n",
            "Bagging Classifier:\n",
            "[[43  1]\n",
            " [ 1 35]]\n",
            "Random Forest Classifier:\n",
            "[[44  0]\n",
            " [ 0 36]]\n",
            "Ada Boost Classifier:\n",
            "[[44  1]\n",
            " [ 0 35]]\n",
            "GBM Classifier:\n",
            "[[44  3]\n",
            " [ 0 33]]\n",
            "XGBoost Classifier:\n",
            "[[44  2]\n",
            " [ 0 34]]\n"
          ]
        }
      ],
      "source": [
        "# Confusion matrix\n",
        "# ---\n",
        "# Regardless of the size of the confusion matrix, the method for intepretation is the same. \n",
        "# The left-hand side contains the predicted values and the actual class labels run across the top. \n",
        "# The instances that the classifier has correctly predicted run diagonally from the top-left \n",
        "# to the bottom-right.\n",
        "# --- \n",
        "# \n",
        "print('Logistic Regression Classifier:') \n",
        "print(confusion_matrix(logistic_y_prediction, y_test))\n",
        "\n",
        "print('Decision Trees Classifier:')\n",
        "print(confusion_matrix(decision_y_prediction, y_test))\n",
        "\n",
        "print('SVN Classifier:')\n",
        "print(confusion_matrix(svm_y_prediction, y_test))\n",
        "\n",
        "print('KNN Classifier:')\n",
        "print(confusion_matrix(knn_y_prediction, y_test))\n",
        "\n",
        "print('Naive Bayes Classifier:')\n",
        "print(confusion_matrix(naive_y_prediction, y_test))\n",
        " \n",
        "print('Bagging Classifier:')\n",
        "print(confusion_matrix(bagging_y_classifier, y_test))\n",
        "\n",
        "print('Random Forest Classifier:')\n",
        "print(confusion_matrix(random_forest_y_classifier, y_test))\n",
        "\n",
        "print('Ada Boost Classifier:')\n",
        "print(confusion_matrix(ada_boost_y_classifier, y_test))\n",
        "\n",
        "print('GBM Classifier:')\n",
        "print(confusion_matrix(gbm_y_classifier, y_test))\n",
        "\n",
        "print('XGBoost Classifier:')\n",
        "print(confusion_matrix(xg_boost_y_classifier, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Matrix Intepretation: Ada Boost Classifier:\n",
        "\n",
        "Looking at Ada Boost matrix, the first rows are False positive is 0's, second row 1's The model predicted 1 of 0's correctly."
      ],
      "metadata": {
        "id": "tcLp0AgDeaBO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "TBJJqpvjp_Nl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff5b1265-c56d-4c70-d1ff-7330ddd0efee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Classifier               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.96      0.98        46\n",
            "           1       0.94      1.00      0.97        34\n",
            "\n",
            "    accuracy                           0.97        80\n",
            "   macro avg       0.97      0.98      0.97        80\n",
            "weighted avg       0.98      0.97      0.98        80\n",
            "\n",
            "Decision Trees Classifier               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.95      0.95        44\n",
            "           1       0.94      0.94      0.94        36\n",
            "\n",
            "    accuracy                           0.95        80\n",
            "   macro avg       0.95      0.95      0.95        80\n",
            "weighted avg       0.95      0.95      0.95        80\n",
            "\n",
            "SVM Classifier               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.92      0.84        37\n",
            "           1       0.92      0.77      0.84        43\n",
            "\n",
            "    accuracy                           0.84        80\n",
            "   macro avg       0.84      0.84      0.84        80\n",
            "weighted avg       0.85      0.84      0.84        80\n",
            "\n",
            "KNN Classifier               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.93      0.93        44\n",
            "           1       0.92      0.92      0.92        36\n",
            "\n",
            "    accuracy                           0.93        80\n",
            "   macro avg       0.92      0.92      0.92        80\n",
            "weighted avg       0.93      0.93      0.93        80\n",
            "\n",
            "Naive Bayes Classifier               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      1.00      0.98        42\n",
            "           1       1.00      0.95      0.97        38\n",
            "\n",
            "    accuracy                           0.97        80\n",
            "   macro avg       0.98      0.97      0.97        80\n",
            "weighted avg       0.98      0.97      0.97        80\n",
            "\n",
            "Bagging Classifier               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98        44\n",
            "           1       0.97      0.97      0.97        36\n",
            "\n",
            "    accuracy                           0.97        80\n",
            "   macro avg       0.97      0.97      0.97        80\n",
            "weighted avg       0.97      0.97      0.97        80\n",
            "\n",
            "Random Forest Classifier               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        44\n",
            "           1       1.00      1.00      1.00        36\n",
            "\n",
            "    accuracy                           1.00        80\n",
            "   macro avg       1.00      1.00      1.00        80\n",
            "weighted avg       1.00      1.00      1.00        80\n",
            "\n",
            "Ada Boost Classifier               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99        45\n",
            "           1       0.97      1.00      0.99        35\n",
            "\n",
            "    accuracy                           0.99        80\n",
            "   macro avg       0.99      0.99      0.99        80\n",
            "weighted avg       0.99      0.99      0.99        80\n",
            "\n",
            "GBM Classifier               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.94      0.97        47\n",
            "           1       0.92      1.00      0.96        33\n",
            "\n",
            "    accuracy                           0.96        80\n",
            "   macro avg       0.96      0.97      0.96        80\n",
            "weighted avg       0.97      0.96      0.96        80\n",
            "\n",
            "XGBoost Classifier               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.96      0.98        46\n",
            "           1       0.94      1.00      0.97        34\n",
            "\n",
            "    accuracy                           0.97        80\n",
            "   macro avg       0.97      0.98      0.97        80\n",
            "weighted avg       0.98      0.97      0.98        80\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Classification Reports\n",
        "# ---\n",
        "#\n",
        "print(\"Logistic Regression Classifier\", classification_report(logistic_y_prediction, y_test))\n",
        "print(\"Decision Trees Classifier\", classification_report(decision_y_prediction, y_test))\n",
        "print(\"SVM Classifier\", classification_report(svm_y_prediction, y_test))\n",
        "print(\"KNN Classifier\", classification_report(knn_y_prediction, y_test))\n",
        "print(\"Naive Bayes Classifier\", classification_report(naive_y_prediction, y_test))\n",
        " \n",
        "print(\"Bagging Classifier\", classification_report(bagging_y_classifier, y_test))\n",
        "print(\"Random Forest Classifier\", classification_report(random_forest_y_classifier, y_test))\n",
        "print(\"Ada Boost Classifier\", classification_report(ada_boost_y_classifier, y_test))\n",
        "print(\"GBM Classifier\", classification_report(gbm_y_classifier, y_test))\n",
        "print(\"XGBoost Classifier\", classification_report(xg_boost_y_classifier, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jA28XDA03Q9-"
      },
      "source": [
        "## <font color='#2F4F4F'>Step 6. Summary of Findings and Recommendation</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our best performing model was Ada Boost Classifier. To improve our model, we can try perfoming other text processing techniques that would better prepare our data for fitting our model. We can also use different vectorizing techniques, implement other machine learning models, perform hyperparameter tuning and sample a balanced dataset."
      ],
      "metadata": {
        "id": "7kFLCm4Xdnky"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qI23jTyh5XDU"
      },
      "source": [
        "## <font color='#2F4F4F'>Step 7. Challenging our Solution</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our best performing model was Ada Boost Classifier. To improve our model, we can try perfoming other text processing techniques that would better prepare our data for fitting our model. We can also use different vectorizing techniques, implement other machine learning models, perform hyperparameter tuning and sample a balanced dataset."
      ],
      "metadata": {
        "id": "2O3o5JXvgr2y"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "XecOwPNorl2W",
        "J4wfHZwQrs-t",
        "a9BPYqunry97",
        "7KMRBJ7zr9HD",
        "qI23jTyh5XDU"
      ],
      "name": "Week 8 Tuesday: Text Classification with Python",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}